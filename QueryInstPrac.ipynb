{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brutal-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setuptools import find_packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mediterranean-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "reflected-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "covered-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "representative-nickname",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mmcv_custom',\n",
       " 'mmdet',\n",
       " 'mmcv_custom.runner',\n",
       " 'mmdet.apis',\n",
       " 'mmdet.core',\n",
       " 'mmdet.datasets',\n",
       " 'mmdet.utils',\n",
       " 'mmdet.models',\n",
       " 'mmdet.core.visualization',\n",
       " 'mmdet.core.post_processing',\n",
       " 'mmdet.core.utils',\n",
       " 'mmdet.core.mask',\n",
       " 'mmdet.core.evaluation',\n",
       " 'mmdet.core.anchor',\n",
       " 'mmdet.core.export',\n",
       " 'mmdet.core.bbox',\n",
       " 'mmdet.core.bbox.match_costs',\n",
       " 'mmdet.core.bbox.iou_calculators',\n",
       " 'mmdet.core.bbox.assigners',\n",
       " 'mmdet.core.bbox.samplers',\n",
       " 'mmdet.core.bbox.coder',\n",
       " 'mmdet.datasets.pipelines',\n",
       " 'mmdet.datasets.api_wrappers',\n",
       " 'mmdet.datasets.samplers',\n",
       " 'mmdet.models.losses',\n",
       " 'mmdet.models.dense_heads',\n",
       " 'mmdet.models.necks',\n",
       " 'mmdet.models.utils',\n",
       " 'mmdet.models.backbones',\n",
       " 'mmdet.models.detectors',\n",
       " 'mmdet.models.roi_heads',\n",
       " 'mmdet.models.roi_heads.shared_heads',\n",
       " 'mmdet.models.roi_heads.roi_extractors',\n",
       " 'mmdet.models.roi_heads.bbox_heads',\n",
       " 'mmdet.models.roi_heads.mask_heads']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_packages(exclude=('configs', 'tools', 'demo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "computational-tourism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yupeng/Documents/2021summer/SummerIntern/QueryInst\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "political-experience",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mmcv_custom',\n",
       " 'mmdet',\n",
       " 'mmcv_custom.runner',\n",
       " 'mmdet.apis',\n",
       " 'mmdet.core',\n",
       " 'mmdet.datasets',\n",
       " 'mmdet.utils',\n",
       " 'mmdet.models',\n",
       " 'mmdet.core.visualization',\n",
       " 'mmdet.core.post_processing',\n",
       " 'mmdet.core.utils',\n",
       " 'mmdet.core.mask',\n",
       " 'mmdet.core.evaluation',\n",
       " 'mmdet.core.anchor',\n",
       " 'mmdet.core.export',\n",
       " 'mmdet.core.bbox',\n",
       " 'mmdet.core.bbox.match_costs',\n",
       " 'mmdet.core.bbox.iou_calculators',\n",
       " 'mmdet.core.bbox.assigners',\n",
       " 'mmdet.core.bbox.samplers',\n",
       " 'mmdet.core.bbox.coder',\n",
       " 'mmdet.datasets.pipelines',\n",
       " 'mmdet.datasets.api_wrappers',\n",
       " 'mmdet.datasets.samplers',\n",
       " 'mmdet.models.losses',\n",
       " 'mmdet.models.dense_heads',\n",
       " 'mmdet.models.necks',\n",
       " 'mmdet.models.utils',\n",
       " 'mmdet.models.backbones',\n",
       " 'mmdet.models.detectors',\n",
       " 'mmdet.models.roi_heads',\n",
       " 'mmdet.models.roi_heads.shared_heads',\n",
       " 'mmdet.models.roi_heads.roi_extractors',\n",
       " 'mmdet.models.roi_heads.bbox_heads',\n",
       " 'mmdet.models.roi_heads.mask_heads']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_packages(exclude=('configs', 'tools'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interracial-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_requirements(fname='requirements.txt', with_version=True):\n",
    "    \"\"\"Parse the package dependencies listed in a requirements file but strips\n",
    "    specific versioning information.\n",
    "\n",
    "    Args:\n",
    "        fname (str): path to requirements file\n",
    "        with_version (bool, default=False): if True include version specs\n",
    "\n",
    "    Returns:\n",
    "        List[str]: list of requirements items\n",
    "\n",
    "    CommandLine:\n",
    "        python -c \"import setup; print(setup.parse_requirements())\"\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    from os.path import exists\n",
    "    import re\n",
    "    require_fpath = fname\n",
    "\n",
    "    def parse_line(line):\n",
    "        \"\"\"Parse information from a line in a requirements text file.\"\"\"\n",
    "        if line.startswith('-r '):\n",
    "            # Allow specifying requirements in other files\n",
    "            target = line.split(' ')[1]\n",
    "            for info in parse_require_file(target):\n",
    "                yield info\n",
    "        else:\n",
    "            info = {'line': line}\n",
    "            if line.startswith('-e '):\n",
    "                info['package'] = line.split('#egg=')[1]\n",
    "            elif '@git+' in line:\n",
    "                info['package'] = line\n",
    "            else:\n",
    "                # Remove versioning from the package\n",
    "                pat = '(' + '|'.join(['>=', '==', '>']) + ')'\n",
    "                parts = re.split(pat, line, maxsplit=1)\n",
    "                parts = [p.strip() for p in parts]\n",
    "\n",
    "                info['package'] = parts[0]\n",
    "                if len(parts) > 1:\n",
    "                    op, rest = parts[1:]\n",
    "                    if ';' in rest:\n",
    "                        # Handle platform specific dependencies\n",
    "                        # http://setuptools.readthedocs.io/en/latest/setuptools.html#declaring-platform-specific-dependencies\n",
    "                        version, platform_deps = map(str.strip,\n",
    "                                                     rest.split(';'))\n",
    "                        info['platform_deps'] = platform_deps\n",
    "                    else:\n",
    "                        version = rest  # NOQA\n",
    "                    info['version'] = (op, version)\n",
    "            yield info\n",
    "\n",
    "    def parse_require_file(fpath):\n",
    "        with open(fpath, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                line = line.strip()\n",
    "                if line and not line.startswith('#'):\n",
    "                    for info in parse_line(line):\n",
    "                        yield info\n",
    "\n",
    "    def gen_packages_items():\n",
    "        if exists(require_fpath):\n",
    "            for info in parse_require_file(require_fpath):\n",
    "                parts = [info['package']]\n",
    "                if with_version and 'version' in info:\n",
    "                    parts.extend(info['version'])\n",
    "                if not sys.version.startswith('3.4'):\n",
    "                    # apparently package_deps are broken in 3.4\n",
    "                    platform_deps = info.get('platform_deps')\n",
    "                    if platform_deps is not None:\n",
    "                        parts.append(';' + platform_deps)\n",
    "                item = ''.join(parts)\n",
    "                yield item\n",
    "\n",
    "    packages = list(gen_packages_items())\n",
    "    return packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interim-chair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cython', 'numpy']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_requirements('requirements/build.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "touched-desire",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asynctest',\n",
       " 'codecov',\n",
       " 'flake8',\n",
       " 'interrogate',\n",
       " 'isort==4.3.21',\n",
       " 'kwarray',\n",
       " 'onnx==1.7.0',\n",
       " 'onnxruntime==1.5.1',\n",
       " 'pytest',\n",
       " 'ubelt',\n",
       " 'xdoctest>=0.10.0',\n",
       " 'yapf']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_requirements('requirements/tests.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "intense-verse",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['matplotlib',\n",
       "  'numpy',\n",
       "  'pycocotools; platform_system==\"Linux\"',\n",
       "  'pycocotools-windows; platform_system==\"Windows\"',\n",
       "  'six',\n",
       "  'terminaltables',\n",
       "  'timm'],)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_requirements('requirements/runtime.txt'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "possible-philadelphia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000],\n",
       "        [0.5000, 0.5000]], grad_fn=<AsStridedBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_proposal_bboxes = nn.Embedding(10, 4)\n",
    "res = nn.init.constant_(init_proposal_bboxes.weight[:, :2], 0.5)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "russian-providence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], grad_fn=<AsStridedBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.constant_(init_proposal_bboxes.weight[:, 2:], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fixed-hudson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0.5000, 0.5000, 1.0000, 1.0000],\n",
       "        [0.5000, 0.5000, 1.0000, 1.0000],\n",
       "        [0.5000, 0.5000, 1.0000, 1.0000],\n",
       "        [0.5000, 0.5000, 1.0000, 1.0000],\n",
       "        [0.5000, 0.5000, 1.0000, 1.0000],\n",
       "        [0.5000, 0.5000, 1.0000, 1.0000],\n",
       "        [0.5000, 0.5000, 1.0000, 1.0000],\n",
       "        [0.5000, 0.5000, 1.0000, 1.0000],\n",
       "        [0.5000, 0.5000, 1.0000, 1.0000],\n",
       "        [0.5000, 0.5000, 1.0000, 1.0000]], requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_proposal_bboxes.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecological-freedom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros((2, 10, 4))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "honey-partner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "talented-training",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = [a[i] for i in range(len(a))]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "interpreted-planet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox2roi(bbox_list):\n",
    "    \"\"\"Convert a list of bboxes to roi format.\n",
    "\n",
    "    Args:\n",
    "        bbox_list (list[Tensor]): a list of bboxes corresponding to a batch\n",
    "            of images.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: shape (n, 5), [batch_ind, x1, y1, x2, y2]\n",
    "    \"\"\"\n",
    "    rois_list = []\n",
    "    for img_id, bboxes in enumerate(bbox_list):\n",
    "        # bboxes.shape: (num_proposals, 4)\n",
    "        if bboxes.size(0) > 0:\n",
    "            img_inds = bboxes.new_full((bboxes.size(0), 1), img_id)\n",
    "            rois = torch.cat([img_inds, bboxes[:, :4]], dim=-1)\n",
    "        else:\n",
    "            rois = bboxes.new_zeros((0, 5))\n",
    "        rois_list.append(rois)\n",
    "    rois = torch.cat(rois_list, 0)\n",
    "    return rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fixed-custom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.4140, 0.7233, 0.4780, 0.1765],\n",
       "        [0.0000, 0.8594, 0.4138, 0.2550, 0.2919],\n",
       "        [1.0000, 0.1803, 0.6177, 0.8708, 0.6756],\n",
       "        [1.0000, 0.6536, 0.2452, 0.3715, 0.2674],\n",
       "        [2.0000, 0.1102, 0.4175, 0.5090, 0.7105],\n",
       "        [2.0000, 0.4338, 0.6390, 0.5860, 0.4554],\n",
       "        [3.0000, 0.8406, 0.4782, 0.0737, 0.2856],\n",
       "        [3.0000, 0.0529, 0.1080, 0.3798, 0.3995]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.rand((4, 2, 4))\n",
    "d = bbox2roi(c)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dramatic-concentrate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "combined-subsection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4140, 0.7233, 0.4780, 0.1765],\n",
       "         [0.8594, 0.4138, 0.2550, 0.2919]],\n",
       "\n",
       "        [[0.1803, 0.6177, 0.8708, 0.6756],\n",
       "         [0.6536, 0.2452, 0.3715, 0.2674]],\n",
       "\n",
       "        [[0.1102, 0.4175, 0.5090, 0.7105],\n",
       "         [0.4338, 0.6390, 0.5860, 0.4554]],\n",
       "\n",
       "        [[0.8406, 0.4782, 0.0737, 0.2856],\n",
       "         [0.0529, 0.1080, 0.3798, 0.3995]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "essential-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "proposal_boxes = torch.rand(4, 2, 4)\n",
    "proposal_list = [proposal_boxes[i] for i in range(len(proposal_boxes))]\n",
    "rois = bbox2roi(proposal_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "extraordinary-rating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.8674, 0.6879, 0.2520, 0.3844],\n",
       "        [0.0000, 0.0416, 0.9977, 0.4560, 0.3463],\n",
       "        [1.0000, 0.2048, 0.4977, 0.6467, 0.9364],\n",
       "        [1.0000, 0.1216, 0.4102, 0.1659, 0.1015],\n",
       "        [2.0000, 0.2531, 0.7194, 0.8648, 0.3340],\n",
       "        [2.0000, 0.2727, 0.6682, 0.8327, 0.1480],\n",
       "        [3.0000, 0.5849, 0.6169, 0.1098, 0.8604],\n",
       "        [3.0000, 0.8024, 0.9218, 0.0160, 0.8042]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "functioning-senator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 340, 340])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels = [2, 3, 5, 7]\n",
    "scales = [340, 170, 84, 43]\n",
    "inputs = [torch.rand(1, c, s, s) for c, s in zip(in_channels, scales)]\n",
    "inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "broken-programming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 170, 170])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "collective-tablet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1859, 0.4968, 0.5601],\n",
       "          [0.1935, 0.3251, 0.7271],\n",
       "          [0.2630, 0.7858, 0.9863]],\n",
       "\n",
       "         [[0.4258, 0.5859, 0.3402],\n",
       "          [0.0410, 0.3063, 0.6568],\n",
       "          [0.9656, 0.2459, 0.9027]],\n",
       "\n",
       "         [[0.5308, 0.5463, 0.0868],\n",
       "          [0.5445, 0.8437, 0.9497],\n",
       "          [0.3916, 0.1916, 0.3441]]],\n",
       "\n",
       "\n",
       "        [[[0.0472, 0.4806, 0.7984],\n",
       "          [0.2977, 0.9824, 0.7561],\n",
       "          [0.5655, 0.2376, 0.6125]],\n",
       "\n",
       "         [[0.8725, 0.2155, 0.0750],\n",
       "          [0.0554, 0.6008, 0.6296],\n",
       "          [0.3653, 0.3989, 0.5753]],\n",
       "\n",
       "         [[0.5374, 0.4930, 0.4973],\n",
       "          [0.5730, 0.6311, 0.8633],\n",
       "          [0.9826, 0.0937, 0.3937]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imgs_whwh.append(imgs[0].new_tensor([[w, h, w, h]]))\n",
    "img_0 = torch.rand((2, 3, 3, 3))\n",
    "img_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "welcome-failing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_0.new_tensor([[2, 2, 2, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bizarre-depth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1005, 0.6047, 0.4954, 0.0234],\n",
       "        [0.5817, 0.8683, 0.5542, 0.7398],\n",
       "        [0.0536, 0.0303, 0.5816, 0.9956]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_whwh = torch.rand((2, 1, 4))\n",
    "proposals = torch.rand((3, 4))\n",
    "proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "center-modem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5256, 0.1174, 0.3877, 0.4371]],\n",
       "\n",
       "        [[0.2512, 0.5584, 0.2768, 0.0615]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs_whwh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acute-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_proposals = proposals * imgs_whwh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hydraulic-young",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_proposals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "stuffed-crest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0528, 0.0710, 0.1921, 0.0102],\n",
       "         [0.3057, 0.1020, 0.2149, 0.3234],\n",
       "         [0.0281, 0.0036, 0.2255, 0.4352]],\n",
       "\n",
       "        [[0.0253, 0.3377, 0.1372, 0.0014],\n",
       "         [0.1461, 0.4848, 0.1534, 0.0455],\n",
       "         [0.0134, 0.0169, 0.1610, 0.0612]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dying-round",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4601,  1.9385, -1.3533],\n",
       "        [-0.0058, -1.2428,  0.0770],\n",
       "        [-0.5888, -0.8354, -1.3720]], requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_proposals = 3\n",
    "proposal_feature_channel = 3\n",
    "init_proposal_features = nn.Embedding(num_proposals, proposal_feature_channel)\n",
    "init_proposal_features.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fundamental-schedule",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4601,  1.9385, -1.3533],\n",
       "        [-0.0058, -1.2428,  0.0770],\n",
       "        [-0.5888, -0.8354, -1.3720]], grad_fn=<CloneBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_proposal_features_weight = init_proposal_features.weight.clone()\n",
    "init_proposal_features_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "compact-exposure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4601,  1.9385, -1.3533],\n",
       "         [-0.0058, -1.2428,  0.0770],\n",
       "         [-0.5888, -0.8354, -1.3720]]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_proposal_features_weight[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "piano-hughes",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-27-bdf5fa19dc76>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-bdf5fa19dc76>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    init_proposal_features_weight[]\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "init_proposal_features_weight[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "photographic-bandwidth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0058, -1.2428,  0.0770], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_proposal_features_weight[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "honey-costume",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_proposal_features_weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "documented-champion",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't use starred expression here (<ipython-input-30-8e71f608340f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-8e71f608340f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    *init_proposal_features_weight.size()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't use starred expression here\n"
     ]
    }
   ],
   "source": [
    "*init_proposal_features_weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "graduate-basin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4601,  1.9385, -1.3533],\n",
       "         [-0.0058, -1.2428,  0.0770],\n",
       "         [-0.5888, -0.8354, -1.3720]],\n",
       "\n",
       "        [[-0.4601,  1.9385, -1.3533],\n",
       "         [-0.0058, -1.2428,  0.0770],\n",
       "         [-0.5888, -0.8354, -1.3720]]], grad_fn=<ExpandBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_imgs = 2\n",
    "init_proposal_features_weight[None].expand(num_imgs, *init_proposal_features_weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "chinese-olympus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_proposal_features_weight[None].expand(num_imgs, *init_proposal_features_weight.size()).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "minute-timing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featmap_strides = [4, 8, 16, 32]\n",
    "len(featmap_strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "prerequisite-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_roi_levels(rois, num_levels):\n",
    "    \"\"\"Map rois to corresponding feature levels by scales.\n",
    "\n",
    "    - scale < finest_scale * 2: level 0\n",
    "    - finest_scale * 2 <= scale < finest_scale * 4: level 1\n",
    "    - finest_scale * 4 <= scale < finest_scale * 8: level 2\n",
    "    - scale >= finest_scale * 8: level 3\n",
    "\n",
    "    Args:\n",
    "        rois (Tensor): Input RoIs, shape (k, 5).\n",
    "        num_levels (int): Total level number.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Level index (0-based) of each RoI, shape (k, )\n",
    "    \"\"\"\n",
    "    # rois: (batch * num_proposals, 5)\n",
    "    scale = torch.sqrt(\n",
    "        (rois[:, 3] - rois[:, 1]) * (rois[:, 4] - rois[:, 2]))\n",
    "    print(scale)\n",
    "    target_lvls = torch.floor(torch.log2(scale / 56 + 1e-6))\n",
    "    print(target_lvls)\n",
    "    target_lvls = target_lvls.clamp(min=0, max=num_levels - 1).long()\n",
    "    return target_lvls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pointed-scope",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.8674, 0.6879, 0.2520, 0.3844],\n",
       "        [0.0000, 0.0416, 0.9977, 0.4560, 0.3463],\n",
       "        [1.0000, 0.2048, 0.4977, 0.6467, 0.9364],\n",
       "        [1.0000, 0.1216, 0.4102, 0.1659, 0.1015],\n",
       "        [2.0000, 0.2531, 0.7194, 0.8648, 0.3340],\n",
       "        [2.0000, 0.2727, 0.6682, 0.8327, 0.1480],\n",
       "        [3.0000, 0.5849, 0.6169, 0.1098, 0.8604],\n",
       "        [3.0000, 0.8024, 0.9218, 0.0160, 0.8042]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "august-installation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4322,    nan, 0.4403,    nan,    nan,    nan,    nan, 0.3041])\n",
      "tensor([-8., nan, -7., nan, nan, nan, nan, -8.])\n"
     ]
    }
   ],
   "source": [
    "map_roi_res = map_roi_levels(rois, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "norwegian-progressive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_roi_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "certified-wellington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([                   0, -9223372036854775808,                    0,\n",
       "        -9223372036854775808, -9223372036854775808, -9223372036854775808,\n",
       "        -9223372036854775808,                    0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_roi_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "coordinate-formation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_roi_res == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "based-magnet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [2., 1., 1., 1., 1.],\n",
       "        [2., 1., 1., 1., 1.],\n",
       "        [3., 1., 1., 1., 1.],\n",
       "        [3., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_one = torch.ones((4, 2, 4))\n",
    "all_one_res = bbox2roi(all_one)\n",
    "all_one_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "spread-disposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_roi_levels(all_one_res, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "narrative-syria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.floor(torch.rand(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "opening-sandwich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.floor(torch.ones(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "hidden-delay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.7629, 0.3841, 0.2630, 0.7933],\n",
       "        [0.0000, 0.7373, 0.4391, 0.9600, 0.6475],\n",
       "        [1.0000, 0.6860, 0.6027, 0.0100, 0.0610],\n",
       "        [1.0000, 0.1370, 0.0319, 0.7754, 0.8904],\n",
       "        [2.0000, 0.2996, 0.0309, 0.0516, 0.9780],\n",
       "        [2.0000, 0.2541, 0.1225, 0.8034, 0.4431],\n",
       "        [3.0000, 0.9790, 0.4394, 0.4774, 0.2575],\n",
       "        [3.0000, 0.1794, 0.8235, 0.9170, 0.6085]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_roi = bbox2roi(torch.rand((4, 2, 4)))\n",
    "test_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "german-vessel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   nan, 0.2154, 0.6051, 0.7404,    nan, 0.4196, 0.3020,    nan])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt((test_roi[:, 3] - test_roi[:, 1]) * (test_roi[:, 4] - test_roi[:, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "built-bridal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2045,  0.0464,  0.3662,  0.5481, -0.2349,  0.1761,  0.0912, -0.1586])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_roi[:, 3] - test_roi[:, 1]) * (test_roi[:, 4] - test_roi[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "editorial-amber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4999,  0.2227, -0.6760,  0.6384, -0.2480,  0.5494, -0.5015,  0.7376])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_roi[:, 3] - test_roi[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "focused-monday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2630, 0.9600, 0.0100, 0.7754, 0.0516, 0.8034, 0.4774, 0.9170])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_roi[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "secure-rings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 7])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = map_roi_res == 0\n",
    "inds = mask.nonzero(as_tuple=False).squeeze(1)\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "wrong-houston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True, False,  True, False, False, False, False,  True])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "recreational-sandwich",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([                   0, -9223372036854775808,                    0,\n",
       "        -9223372036854775808, -9223372036854775808, -9223372036854775808,\n",
       "        -9223372036854775808,                    0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_roi_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "hollow-personality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [2],\n",
       "        [7]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.nonzero(as_tuple=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "official-black",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.7629, 0.3841, 0.2630, 0.7933],\n",
       "        [0.0000, 0.7373, 0.4391, 0.9600, 0.6475],\n",
       "        [1.0000, 0.6860, 0.6027, 0.0100, 0.0610],\n",
       "        [1.0000, 0.1370, 0.0319, 0.7754, 0.8904],\n",
       "        [2.0000, 0.2996, 0.0309, 0.0516, 0.9780],\n",
       "        [2.0000, 0.2541, 0.1225, 0.8034, 0.4431],\n",
       "        [3.0000, 0.9790, 0.4394, 0.4774, 0.2575],\n",
       "        [3.0000, 0.1794, 0.8235, 0.9170, 0.6085]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "promotional-buying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.7629, 0.3841, 0.2630, 0.7933],\n",
       "        [1.0000, 0.6860, 0.6027, 0.0100, 0.0610],\n",
       "        [3.0000, 0.1794, 0.8235, 0.9170, 0.6085]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_roi[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "processed-commission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 7])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "adopted-storage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6784, 0.7932, 0.5145],\n",
       "         [0.0992, 0.0859, 0.5313]],\n",
       "\n",
       "        [[0.4867, 0.9737, 0.1892],\n",
       "         [0.3729, 0.2131, 0.0048]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal_feat = torch.rand((2, 2, 3))\n",
    "proposal_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "charming-cleaning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6784, 0.7932, 0.5145],\n",
       "         [0.4867, 0.9737, 0.1892]],\n",
       "\n",
       "        [[0.0992, 0.0859, 0.5313],\n",
       "         [0.3729, 0.2131, 0.0048]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposal_feat.permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "geographic-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new_zeros = torch.rand((2, 3, 4))\n",
    "test_new_zeros_1 = torch.rand((2, 4))\n",
    "gen = test_new_zeros.new_zeros(len(test_new_zeros))\n",
    "gen_1 = test_new_zeros_1.new_zeros(len(test_new_zeros_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "flexible-vancouver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "structural-wyoming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dying-pontiac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8472, 0.7459, 0.4239, 0.9840])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new_zeros_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nuclear-bedroom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new_zeros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "subjective-glenn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.3887, 2.9836, 1.6955, 3.9359],\n",
       "        [2.0148, 0.6900, 0.7875, 2.2636]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new_zeros_1 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cellular-impression",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = torch.rand(3)\n",
    "inds = torch.stack((label, label + 1, label + 2, label + 3), 1)\n",
    "inds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "prostate-singer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0178, 0.2046, 0.7053])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "herbal-latitude",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0178, 1.0178, 2.0178, 3.0178],\n",
       "        [0.2046, 1.2046, 2.2046, 3.2046],\n",
       "        [0.7053, 1.7053, 2.7053, 3.7053]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "annual-combining",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (1) must match the existing size (3) at non-singleton dimension 0.  Target sizes: [1].  Tensor sizes: [3]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-83fb71d33aa0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpos_keep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpos_is_gts_\u001b[0m  \u001b[0;31m# (num_proposals,) 实际上全是1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkeep_inds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_is_gts_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rois\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (num_rois, )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mkeep_inds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_is_gts_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_keep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (3) at non-singleton dimension 0.  Target sizes: [1].  Tensor sizes: [3]"
     ]
    }
   ],
   "source": [
    "num_rois = 1\n",
    "num_proposals = 3\n",
    "pos_is_gts_ = torch.ones(num_proposals)\n",
    "pos_keep = 1 - pos_is_gts_  # (num_proposals,) 实际上全是1\n",
    "keep_inds = pos_is_gts_.new_ones(num_rois)  # (num_rois, )\n",
    "keep_inds[:len(pos_is_gts_)] = pos_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dedicated-strip",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[None] * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "voluntary-reduction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_res_none = [None] * 1\n",
    "type(get_res_none[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "precise-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = json.load(open('../vis2021/results.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "perceived-elite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['video_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "linear-influence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3244"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "smart-lucas",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " {'size': [720, 1280],\n",
       "  'counts': 'Xab;5Yf03M2O1N2O1O1O0010O10O100000MQZODPf0<PZOEPf0>O000010O00001O001O001O0O1LmYOJTf06lYOIUf0720001O00hYOJVf09O001O00010O000001O0O2O00[P_?'},\n",
       " None,\n",
       " None,\n",
       " {'size': [720, 1280],\n",
       "  'counts': 'dah02Vf0;G7M4M2N101N101O1O1N101O001O01O010O100O010O2O1N2O1O0O2O0O1O100O00100O010O00100O01O010O001O0000001O01O01O001O00001O00001N1000001O001O0000001O0O100O2M2M3N2O2N1010O01O1O010O001O01O01O01O01O001O0010O01O01O01O0010O01O00001O001O01O01O00010O000010O02N0001O000000001O000000001O00001O0000001O0000001O00001O001O00001O0000001O00001O00001O001O0000001O00001O00001O000000001O0000000000001O00000000001O001O001O001O001O1O1O001O2N1O1O001O1O1O002N1O1O1O000000QZ_f0'},\n",
       " {'size': [720, 1280],\n",
       "  'counts': 'Y[`33]f000000000000000001O01O01O005K1O2N3M2N2N1O1001O1O0000O100O100O006J1O00100O001O1O001O001O01O0001O000000001O000000000000001O000000001O1O001O1O1O1[[OjNnc0W1o[OmNoc0T1n[OoNQd0R1m[OoNSd0R1j[OQOUd0P1i[OQOWd0o0i[OQOWd0Q1f[OQOYd0c1000000001O000O10000000000000000O101N1O1N2O100O1O10000O100O1O2N1O1N2M3K5M3N2L400O100O10000000001O00000000000000000010O00001O01O01O00001O0001O01O000001O000010O0001O000001O01O0000001O00001O1O00001O00001O00001O1O001O001O1O1O001O001O1O10O01O1O2N1O1O010O0010O0001O00001O001O0000001O000000001O2NUX;OlgD0O1O10001N10000O2O00000O10001N10000O100O101O0O10000O100O1O1O1O1N2N2O1000000O101O00001O001O001O001O0O2O001O1O2N1O2N1O2N2N2N2N1O1O2N100O1O1O1O1O1O2N2N2N0001O0000000000000000O1000000000WOa[OA_d0>c[OA]d0>e[OA[d0>f[OBZd0=h[OBXd0>i[OAVd0?l[O@Td0`0m[O_OSd0a0n[O^ORd0a0P\\\\O^Ooc0c0R\\\\O\\\\Onc0c0T\\\\O\\\\Olc0d0V\\\\OZOic0g0X\\\\OXOhc0h0Y\\\\OTOjc0k0X\\\\OTOhc0l0Z\\\\OQOgc0o0Z\\\\OoNfc0R1l00000000000O10000000000000000000O0100000000O10000O1000000O10000O100O1O1O100O1O100O1000000000000000f[j?'},\n",
       " {'size': [720, 1280],\n",
       "  'counts': 'kfa59Wf000000000000000001O00001O1O001O001O001O01O010O0010O1O010O100O0010O000001O01O01O001O001O010O00001O01O01O001O010O001O01O000001O01O01O001O1O2N1hZOYOfd0g0U[O_OHLjd0g0[[OK_d08][OJbd0S1O1O000000000001O000000000000000O100O100O1O1O100O2O0O10000O10000O1O1O1L4@`0N3M200O1000000O100000000O10001O000O10000001O000001O01O0000000010O00000000001O01O0001O00000010O01O1O1O001O100O001O1O001O000010O000001O00000010O000001O0001O01O00000010O000001O01O0000000001O0000000000000000001O01O0000000001O00000000000001O000000000O101O00000000000000000000000000001O000000000O10000000O100000000000O2O0000001O00001O1N2O1O2N1WZO\\\\Ode0i0O1O1O2M2O1O2N1O1O1O1O1O001O0O2O001O1O1O2N1O2N00000000000O10000000000O10000000QOZ[O4fd0K\\\\[O4dd0L\\\\[O4cd0L_[O3ad0M`[O2`d0Na[O1_d0Ob[O0]d01d[ON\\\\d02f[OLYd04j[OJVd06m[OGSd09n[OFQd0;P\\\\OBRd0>P\\\\O_OQd0a0P\\\\O]OQd0c0m010000000O01000000O100000000000O01000000000O1000O10O100000000O10000O10000O100O10000O100000000000mnT>'},\n",
       " {'size': [720, 1280],\n",
       "  'counts': 'l\\\\h65[f000000000000000001O001O001O001O000010O0000010O01O00100O00001O0000000010O0001O00001O0000001O00010O1O1O2N1O2ZZODMHRe0f0lZONPe0j0O1O001O1O001O001O00001O00000000000000O10000000000O10000O100O100L4L4M3M3K5J6O1N2O10001N1O100O10000O1000001O000000000000001O00000001O0001O01O00010O000001O01O01O00001O00001O00001O00001O0010O0001O0000001O0001O000001O00000000000000000000000001O01O0000000001O0000000000000000000000000001O00000001O000001O000000000000000000000000O2O0000000000000000000O1000000000000000001O000000000000001O00001O2N2N<D2N1O1O001O0000001O001O001O001O1O001O0000001O00000000001O00000O10000000WOoZO3Qe0KV[O0jd0OY[OOgd01Z[OMgd02[[OMdd04\\\\[OLdd03^[OLbd04^[OLbd04_[OKad05_[OKad05`[OJ`d06`[OIad07`[OH`d08a[OF`d0:a[OE_d0;c[OB^d0=k00O100000000000000O10000000000O10000O010O100O10O10O10000O0100000O010000O010O1000O010000000000000lRd='},\n",
       " {'size': [720, 1280],\n",
       "  'counts': 'ZPT81_f0000000000000002N00100O1O00001O001O00001O00100O001O00001O01O0001O01O0001O0000010O000001O0010O0001O0000010O0001O1O1Ob0^O2N100O0kZOPOjd0Q1S[OQOmd0P1Q[OROnd0X101O001O0000001O01O00O10000000000000000000000000O10000O1O1G9M300O2FbZO]Oae0`09O1O1N2O1O10000O1000001O0000000000001O000000001O0000000000001O000001O01O0000001O000000000000001O01O00000000000001O000000000000001O00000000000000001O0000000000001O0O1OQYb00Pg]O1O00001O000000000000000O101O0000001N2O1O3M;E2M2O1O001O00001N10001O0000001N1000000O2O000O10000O2O000000001O0000001O00VOkZO9Ue0GmZO7Se0HP[O6Pe0JP[O6Pe0JQ[O5od0KR[O4nd0LS[O3md0MU[O1kd0OV[O0jd00X[OMid03Y[OKgd05Z[OJfd06Z[OJfd06\\\\[OHdd08][OFdd0:i000000O1000000000000O0100000O10O10O100000O10O1000O10O10O1000O10O100000000000_bm<'},\n",
       " {'size': [720, 1280],\n",
       "  'counts': 'lmX:1^f03M10001O001O00001O000000001O0000000010O000001O0000001O001O1O001O103L3M2N3M2N2N2N2N1O001O001O00001O000000000000000000000000000000000000O100FfZO^OZe0a0jZO[OWe0d0kZO[OUe0c0oZOZORe0e0=M3O1O100O1O100000000000000000001O0000000000001O00000000001O0000001O0000001O00000000000000001O01O0000000000O10000000001O01O0000000000000001O000000000000000000000000000000001O000000000000000000000O100001O000000000O1000001O001O2M4M4L2N1N2O001O00000O2O0000001O0000001N101O0000001O0000000000001O000O100000O10000]OjZOKWe05lZOHTe07oZOGQe09P[OEPe0<Q[OCod0<c00000000O100000O10O10000O100O1O010O1O10000O01000O010O010O0100000000000mmm;'},\n",
       " {'size': [720, 1280],\n",
       "  'counts': 'baQ;3[f04K4M2O2N100O100O1O1O001N2O1O0N3M3N2O0010O010O010O010O0100O0010O0100O1O1O2O0O2N101O0O2N1O2N1O2N1O2N1O2N1O1OWO][OGcd04d[OJ[d05i[OIVd07l[OHSd07P\\\\OHPd08P\\\\OHoc08S\\\\OFnc09T\\\\OElc0;V\\\\OCjc0=Y\\\\O@gc0`0`\\\\OYO`c0h0T1O010O01O01N10000001O01O00000000001O01O01O0O10O1O100O10010O00O100000000000000000O101O00010O000N2O1O2O001O001O10O01O010O010000O01000O10000O010000O100000O0100000O0100O0100O010O0100O10O0100O1O010O001N101O001O00000O1O1OO01O10O4N2L4M3M3M4L3M4M1O100000^fm<'},\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]['segmentations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prospective-posting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "enhanced-single",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vidIds = [[]]\n",
    "len(vidIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "contrary-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _isArrayLike(obj):\n",
    "    return hasattr(obj, '__iter__') and hasattr(obj, '__len__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "internal-causing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_isArrayLike([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "molecular-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {1: \"aaa\", 2: \"bbb\"}\n",
    "ids = dict1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "voluntary-repair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "married-heritage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in ids:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "united-housing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "educated-photography",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance((1, 2), list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "smoking-leader",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5dd84226f532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvid\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mframe_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "vid,  frame_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "italic-blogger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "sixth-holder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "measured-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 2]]\n",
    "b = np.array(a, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "perceived-affiliate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "reasonable-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "vidToAnns = defaultdict(list)\n",
    "vidToAnns[1].append({1: 2})\n",
    "vidToAnns[1].append({1: 3})\n",
    "vidToAnns[2].append({2: 2})\n",
    "vidToAnns[2].append({2: 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "generous-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "vidIds = [1, 2]\n",
    "lists = [vidToAnns[vidId] for vidId in vidIds if vidId in vidToAnns]\n",
    "anns = list(itertools.chain.from_iterable(lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rubber-least",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{1: 2}, {1: 3}], [{2: 2}, {2: 3}]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "expanded-shepherd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1: 2}, {1: 3}, {2: 2}, {2: 3}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "limiting-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ids = []\n",
    "img_ids.append((0, 1))\n",
    "img_ids.append((0, 2))\n",
    "img_ids.append((1, 1))\n",
    "img_ids.append((1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "tracked-daniel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "known-quality",
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = [None, [1,2], None, [3, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "photographic-berlin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, [1, 2], None, [3, 4]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "rolled-correction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bboxes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "million-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_scale(img_scales, mode='range'):\n",
    "    \"\"\"Randomly select a scale from a list of scales or scale ranges.\n",
    "\n",
    "    Args:\n",
    "        img_scales (list[tuple]): Image scale or scale range.\n",
    "        mode (str): \"range\" or \"value\".\n",
    "\n",
    "    Returns:\n",
    "        tuple: Sampled image scale.\n",
    "    \"\"\"\n",
    "    num_scales = len(img_scales)\n",
    "    if num_scales == 1:  # fixed scale is specified\n",
    "        img_scale = img_scales[0]\n",
    "    elif num_scales == 2:  # randomly sample a scale\n",
    "        if mode == 'range':\n",
    "            img_scale_long = [max(s) for s in img_scales]\n",
    "            img_scale_short = [min(s) for s in img_scales]\n",
    "            long_edge = np.random.randint(\n",
    "                min(img_scale_long),\n",
    "                max(img_scale_long) + 1)\n",
    "            short_edge = np.random.randint(\n",
    "                min(img_scale_short),\n",
    "                max(img_scale_short) + 1)\n",
    "            img_scale = (long_edge, short_edge)\n",
    "        elif mode == 'value':\n",
    "            img_scale = img_scales[np.random.randint(num_scales)]\n",
    "    else:\n",
    "        if mode != 'value':\n",
    "            raise ValueError(\n",
    "                'Only \"value\" mode supports more than 2 image scales')\n",
    "        img_scale = img_scales[np.random.randint(num_scales)]\n",
    "    return img_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "equipped-water",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405, 240)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_scale([(640, 260), (320, 130)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "noted-amateur",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 185)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_scale([(640, 260), (320, 130)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "informational-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(x):\n",
    "    if x==2:\n",
    "        return 4\n",
    "    return 6\n",
    "def b(x):\n",
    "    if x==1:\n",
    "        return 2\n",
    "    return 3\n",
    "@a\n",
    "@b\n",
    "def test_at():\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "green-anatomy",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-4d9b9e6dca63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "test_at()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "referenced-testament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "hollow-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg=dict(\n",
    "    type='QueryInst',\n",
    "    pretrained='torchvision://resnet50',\n",
    "    backbone=dict(\n",
    "        type='ResNet',\n",
    "        depth=50,\n",
    "        num_stages=4,\n",
    "        out_indices=(0, 1, 2, 3),\n",
    "        frozen_stages=1,\n",
    "        norm_cfg=dict(type='BN', requires_grad=True),\n",
    "        norm_eval=True,\n",
    "        style='pytorch')\n",
    "    )\n",
    "train_cfg=dict(\n",
    "        rpn=None,\n",
    "        )\n",
    "\n",
    "test_cfg=dict(rpn=None, mask_thr_binary=0.5, nms=dict(type='nms', iou_threshold=0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "affecting-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = cfg.copy()\n",
    "default_args = dict(train_cfg=train_cfg, test_cfg=test_cfg)\n",
    "if default_args is not None:\n",
    "    for name, value in default_args.items():\n",
    "        args.setdefault(name, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "patient-vegetation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'QueryInst',\n",
       " 'pretrained': 'torchvision://resnet50',\n",
       " 'backbone': {'type': 'ResNet',\n",
       "  'depth': 50,\n",
       "  'num_stages': 4,\n",
       "  'out_indices': (0, 1, 2, 3),\n",
       "  'frozen_stages': 1,\n",
       "  'norm_cfg': {'type': 'BN', 'requires_grad': True},\n",
       "  'norm_eval': True,\n",
       "  'style': 'pytorch'},\n",
       " 'train_cfg': {'rpn': None},\n",
       " 'test_cfg': {'rpn': None,\n",
       "  'mask_thr_binary': 0.5,\n",
       "  'nms': {'type': 'nms', 'iou_threshold': 0.7}}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "chief-transcription",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "owned-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((2, 3))\n",
    "x_n = 2\n",
    "x_split = torch.split(x, x_n, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "indirect-trust",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-13871fd04bb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mprod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprods\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "prods = []\n",
    "for i in range(x_n):\n",
    "    prod = torch.mm(x_split[i], torch.transpose(x_split[i], 0, 1))\n",
    "    prods.append(prod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "identified-princeton",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = collections.OrderedDict([('bbox_mAP', 0.469), ('bbox_mAP_50', 0.659), ('bbox_mAP_75', 0.514), ('bbox_mAP_s', 0.302), ('bbox_mAP_m', 0.496), ('bbox_mAP_l', 0.617), ('bbox_mAP_copypaste', '0.469 0.659 0.514 0.302 0.496 0.617'), ('segm_mAP', 0.414), ('segm_mAP_50', 0.638), ('segm_mAP_75', 0.451), ('segm_mAP_s', 0.231), ('segm_mAP_m', 0.443), ('segm_mAP_l', 0.598), ('segm_mAP_copypaste', '0.414 0.638 0.451 0.231 0.443 0.598')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "french-cache",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox_mAP', 0.469),\n",
       "             ('bbox_mAP_50', 0.659),\n",
       "             ('bbox_mAP_75', 0.514),\n",
       "             ('bbox_mAP_s', 0.302),\n",
       "             ('bbox_mAP_m', 0.496),\n",
       "             ('bbox_mAP_l', 0.617),\n",
       "             ('bbox_mAP_copypaste', '0.469 0.659 0.514 0.302 0.496 0.617'),\n",
       "             ('segm_mAP', 0.414),\n",
       "             ('segm_mAP_50', 0.638),\n",
       "             ('segm_mAP_75', 0.451),\n",
       "             ('segm_mAP_s', 0.231),\n",
       "             ('segm_mAP_m', 0.443),\n",
       "             ('segm_mAP_l', 0.598),\n",
       "             ('segm_mAP_copypaste', '0.414 0.638 0.451 0.231 0.443 0.598')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pediatric-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {'dataset_type': 'CocoDataset', 'data_root': 'data/coco/', 'img_norm_cfg': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'train_pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'img_scale': (1333, 800), 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}], 'test_pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}], 'data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'train': {'type': 'CocoDataset', 'ann_file': 'data/coco/annotations/instances_train2017.json', 'img_prefix': 'data/coco/train2017/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'img_scale': (1333, 800), 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}, 'val': {'type': 'CocoDataset', 'ann_file': 'data/coco/annotations/instances_val2017.json', 'img_prefix': 'data/coco/val2017/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}]}, 'test': {'type': 'CocoDataset', 'ann_file': 'data/coco/annotations/instances_val2017.json', 'img_prefix': 'data/coco/val2017/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}]}}, 'evaluation': {'metric': ['bbox', 'segm']}, 'optimizer': {'type': 'AdamW', 'lr': 2.5e-05, 'weight_decay': 0.0001}, 'optimizer_config': {'grad_clip': {'max_norm': 1, 'norm_type': 2}}, 'lr_config': {'policy': 'step', 'warmup': 'linear', 'warmup_iters': 1000, 'warmup_ratio': 0.001, 'step': [8, 11]}, 'runner': {'type': 'EpochBasedRunner', 'max_epochs': 12}, 'checkpoint_config': {'interval': 1}, 'log_config': {'interval': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'custom_hooks': [{'type': 'NumClassCheckHook'}], 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'num_stages': 6, 'num_proposals': 100, 'model': {'type': 'QueryInst', 'pretrained': 'torchvision://resnet50', 'backbone': {'type': 'ResNet', 'depth': 50, 'num_stages': 4, 'out_indices': (0, 1, 2, 3), 'frozen_stages': 1, 'norm_cfg': {'type': 'BN', 'requires_grad': True}, 'norm_eval': True, 'style': 'pytorch'}, 'neck': {'type': 'FPN', 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256, 'start_level': 0, 'add_extra_convs': 'on_input', 'num_outs': 4}, 'rpn_head': {'type': 'EmbeddingRPNHead', 'num_proposals': 100, 'proposal_feature_channel': 256}, 'roi_head': {'type': 'QueryRoIHead', 'num_stages': 6, 'stage_loss_weights': [1, 1, 1, 1, 1, 1], 'proposal_feature_channel': 256, 'bbox_roi_extractor': {'type': 'SingleRoIExtractor', 'roi_layer': {'type': 'RoIAlign', 'output_size': 7, 'sampling_ratio': 2}, 'out_channels': 256, 'featmap_strides': [4, 8, 16, 32]}, 'mask_roi_extractor': {'type': 'SingleRoIExtractor', 'roi_layer': {'type': 'RoIAlign', 'output_size': 14, 'sampling_ratio': 2}, 'out_channels': 256, 'featmap_strides': [4, 8, 16, 32]}, 'bbox_head': [{'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}], 'mask_head': [{'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}]}, 'train_cfg': {'rpn': None, 'rcnn': [{'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}]}, 'test_cfg': {'rpn': None, 'rcnn': {'max_per_img': 100, 'mask_thr_binary': 0.5, 'nms': {'type': 'nms', 'iou_threshold': 0.7}}}}, 'total_epochs': 12, 'work_dir': './work_dirs/queryinst_r50_fpn_1x_coco', 'gpu_ids': range(0, 1), 'seed': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "phantom-synthesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stopped-gateway",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_type:CocoDataset\n",
      "data_root:data/coco/\n",
      "img_norm_cfg:{'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}\n",
      "train_pipeline:[{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'img_scale': (1333, 800), 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]\n",
      "test_pipeline:[{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}]\n",
      "data:{'samples_per_gpu': 2, 'workers_per_gpu': 2, 'train': {'type': 'CocoDataset', 'ann_file': 'data/coco/annotations/instances_train2017.json', 'img_prefix': 'data/coco/train2017/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'img_scale': (1333, 800), 'keep_ratio': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}, 'val': {'type': 'CocoDataset', 'ann_file': 'data/coco/annotations/instances_val2017.json', 'img_prefix': 'data/coco/val2017/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}]}, 'test': {'type': 'CocoDataset', 'ann_file': 'data/coco/annotations/instances_val2017.json', 'img_prefix': 'data/coco/val2017/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}]}}\n",
      "evaluation:{'metric': ['bbox', 'segm']}\n",
      "optimizer:{'type': 'AdamW', 'lr': 2.5e-05, 'weight_decay': 0.0001}\n",
      "optimizer_config:{'grad_clip': {'max_norm': 1, 'norm_type': 2}}\n",
      "lr_config:{'policy': 'step', 'warmup': 'linear', 'warmup_iters': 1000, 'warmup_ratio': 0.001, 'step': [8, 11]}\n",
      "runner:{'type': 'EpochBasedRunner', 'max_epochs': 12}\n",
      "checkpoint_config:{'interval': 1}\n",
      "log_config:{'interval': 50, 'hooks': [{'type': 'TextLoggerHook'}]}\n",
      "custom_hooks:[{'type': 'NumClassCheckHook'}]\n",
      "dist_params:{'backend': 'nccl'}\n",
      "log_level:INFO\n",
      "load_from:None\n",
      "resume_from:None\n",
      "workflow:[('train', 1)]\n",
      "num_stages:6\n",
      "num_proposals:100\n",
      "model:{'type': 'QueryInst', 'pretrained': 'torchvision://resnet50', 'backbone': {'type': 'ResNet', 'depth': 50, 'num_stages': 4, 'out_indices': (0, 1, 2, 3), 'frozen_stages': 1, 'norm_cfg': {'type': 'BN', 'requires_grad': True}, 'norm_eval': True, 'style': 'pytorch'}, 'neck': {'type': 'FPN', 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256, 'start_level': 0, 'add_extra_convs': 'on_input', 'num_outs': 4}, 'rpn_head': {'type': 'EmbeddingRPNHead', 'num_proposals': 100, 'proposal_feature_channel': 256}, 'roi_head': {'type': 'QueryRoIHead', 'num_stages': 6, 'stage_loss_weights': [1, 1, 1, 1, 1, 1], 'proposal_feature_channel': 256, 'bbox_roi_extractor': {'type': 'SingleRoIExtractor', 'roi_layer': {'type': 'RoIAlign', 'output_size': 7, 'sampling_ratio': 2}, 'out_channels': 256, 'featmap_strides': [4, 8, 16, 32]}, 'mask_roi_extractor': {'type': 'SingleRoIExtractor', 'roi_layer': {'type': 'RoIAlign', 'output_size': 14, 'sampling_ratio': 2}, 'out_channels': 256, 'featmap_strides': [4, 8, 16, 32]}, 'bbox_head': [{'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}], 'mask_head': [{'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}]}, 'train_cfg': {'rpn': None, 'rcnn': [{'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}]}, 'test_cfg': {'rpn': None, 'rcnn': {'max_per_img': 100, 'mask_thr_binary': 0.5, 'nms': {'type': 'nms', 'iou_threshold': 0.7}}}}\n",
      "total_epochs:12\n",
      "work_dir:./work_dirs/queryinst_r50_fpn_1x_coco\n",
      "gpu_ids:range(0, 1)\n",
      "seed:None\n"
     ]
    }
   ],
   "source": [
    "for key,value in cfg.items():\n",
    "    print('{key}:{value}'.format(key = key, value = value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "combined-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg1 = {'dataset_type': 'CocoDataset', 'data_root': 'data/coco/', 'img_norm_cfg': {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, 'train_pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'AutoAugment', 'policies': [[{'type': 'Resize', 'img_scale': [(480, 1333), (512, 1333), (544, 1333), (576, 1333), (608, 1333), (640, 1333), (672, 1333), (704, 1333), (736, 1333), (768, 1333), (800, 1333)], 'multiscale_mode': 'value', 'keep_ratio': True}], [{'type': 'Resize', 'img_scale': [(400, 1333), (500, 1333), (600, 1333)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_type': 'absolute_range', 'crop_size': (384, 600), 'allow_negative_crop': True}, {'type': 'Resize', 'img_scale': [(480, 1333), (512, 1333), (544, 1333), (576, 1333), (608, 1333), (640, 1333), (672, 1333), (704, 1333), (736, 1333), (768, 1333), (800, 1333)], 'multiscale_mode': 'value', 'override': True, 'keep_ratio': True}]]}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}], 'test_pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}], 'data': {'samples_per_gpu': 2, 'workers_per_gpu': 2, 'train': {'type': 'CocoDataset', 'ann_file': 'data/coco/annotations/instances_train2017.json', 'img_prefix': 'data/coco/train2017/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'AutoAugment', 'policies': [[{'type': 'Resize', 'img_scale': [(480, 1333), (512, 1333), (544, 1333), (576, 1333), (608, 1333), (640, 1333), (672, 1333), (704, 1333), (736, 1333), (768, 1333), (800, 1333)], 'multiscale_mode': 'value', 'keep_ratio': True}], [{'type': 'Resize', 'img_scale': [(400, 1333), (500, 1333), (600, 1333)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_type': 'absolute_range', 'crop_size': (384, 600), 'allow_negative_crop': True}, {'type': 'Resize', 'img_scale': [(480, 1333), (512, 1333), (544, 1333), (576, 1333), (608, 1333), (640, 1333), (672, 1333), (704, 1333), (736, 1333), (768, 1333), (800, 1333)], 'multiscale_mode': 'value', 'override': True, 'keep_ratio': True}]]}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}, 'val': {'type': 'CocoDataset', 'ann_file': 'data/coco/annotations/instances_val2017.json', 'img_prefix': 'data/coco/val2017/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}]}, 'test': {'type': 'CocoDataset', 'ann_file': 'data/coco/annotations/instances_val2017.json', 'img_prefix': 'data/coco/val2017/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}]}}, 'evaluation': {'metric': ['bbox', 'segm']}, 'optimizer': {'type': 'AdamW', 'lr': 2.5e-05, 'weight_decay': 0.0001}, 'optimizer_config': {'grad_clip': {'max_norm': 1, 'norm_type': 2}}, 'lr_config': {'policy': 'step', 'warmup': 'linear', 'warmup_iters': 1000, 'warmup_ratio': 0.001, 'step': [27, 33]}, 'runner': {'type': 'EpochBasedRunner', 'max_epochs': 36}, 'checkpoint_config': {'interval': 1}, 'log_config': {'interval': 50, 'hooks': [{'type': 'TextLoggerHook'}]}, 'custom_hooks': [{'type': 'NumClassCheckHook'}], 'dist_params': {'backend': 'nccl'}, 'log_level': 'INFO', 'load_from': None, 'resume_from': None, 'workflow': [('train', 1)], 'num_stages': 6, 'num_proposals': 300, 'model': {'type': 'QueryInst', 'pretrained': 'torchvision://resnet50', 'backbone': {'type': 'ResNet', 'depth': 50, 'num_stages': 4, 'out_indices': (0, 1, 2, 3), 'frozen_stages': 1, 'norm_cfg': {'type': 'BN', 'requires_grad': True}, 'norm_eval': True, 'style': 'pytorch'}, 'neck': {'type': 'FPN', 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256, 'start_level': 0, 'add_extra_convs': 'on_input', 'num_outs': 4}, 'rpn_head': {'type': 'EmbeddingRPNHead', 'num_proposals': 300, 'proposal_feature_channel': 256}, 'roi_head': {'type': 'QueryRoIHead', 'num_stages': 6, 'stage_loss_weights': [1, 1, 1, 1, 1, 1], 'proposal_feature_channel': 256, 'bbox_roi_extractor': {'type': 'SingleRoIExtractor', 'roi_layer': {'type': 'RoIAlign', 'output_size': 7, 'sampling_ratio': 2}, 'out_channels': 256, 'featmap_strides': [4, 8, 16, 32]}, 'mask_roi_extractor': {'type': 'SingleRoIExtractor', 'roi_layer': {'type': 'RoIAlign', 'output_size': 14, 'sampling_ratio': 2}, 'out_channels': 256, 'featmap_strides': [4, 8, 16, 32]}, 'bbox_head': [{'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}], 'mask_head': [{'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}]}, 'train_cfg': {'rpn': None, 'rcnn': [{'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}]}, 'test_cfg': {'rpn': None, 'rcnn': {'max_per_img': 300, 'mask_thr_binary': 0.5, 'nms': {'type': 'nms', 'iou_threshold': 0.7}}}}, 'total_epochs': 36, 'min_values': (480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800), 'work_dir': './work_dirs/queryinst_r50_fpn_300_proposals_crop_mstrain_480-800_3x_coco', 'gpu_ids': range(0, 1), 'seed': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "important-distinction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_type:CocoDataset\n",
      "data_root:data/coco/\n",
      "img_norm_cfg:{'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}\n",
      "train_pipeline:[{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'AutoAugment', 'policies': [[{'type': 'Resize', 'img_scale': [(480, 1333), (512, 1333), (544, 1333), (576, 1333), (608, 1333), (640, 1333), (672, 1333), (704, 1333), (736, 1333), (768, 1333), (800, 1333)], 'multiscale_mode': 'value', 'keep_ratio': True}], [{'type': 'Resize', 'img_scale': [(400, 1333), (500, 1333), (600, 1333)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_type': 'absolute_range', 'crop_size': (384, 600), 'allow_negative_crop': True}, {'type': 'Resize', 'img_scale': [(480, 1333), (512, 1333), (544, 1333), (576, 1333), (608, 1333), (640, 1333), (672, 1333), (704, 1333), (736, 1333), (768, 1333), (800, 1333)], 'multiscale_mode': 'value', 'override': True, 'keep_ratio': True}]]}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]\n",
      "test_pipeline:[{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}]\n",
      "data:{'samples_per_gpu': 2, 'workers_per_gpu': 2, 'train': {'type': 'CocoDataset', 'ann_file': 'data/coco/annotations/instances_train2017.json', 'img_prefix': 'data/coco/train2017/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'AutoAugment', 'policies': [[{'type': 'Resize', 'img_scale': [(480, 1333), (512, 1333), (544, 1333), (576, 1333), (608, 1333), (640, 1333), (672, 1333), (704, 1333), (736, 1333), (768, 1333), (800, 1333)], 'multiscale_mode': 'value', 'keep_ratio': True}], [{'type': 'Resize', 'img_scale': [(400, 1333), (500, 1333), (600, 1333)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_type': 'absolute_range', 'crop_size': (384, 600), 'allow_negative_crop': True}, {'type': 'Resize', 'img_scale': [(480, 1333), (512, 1333), (544, 1333), (576, 1333), (608, 1333), (640, 1333), (672, 1333), (704, 1333), (736, 1333), (768, 1333), (800, 1333)], 'multiscale_mode': 'value', 'override': True, 'keep_ratio': True}]]}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}, 'val': {'type': 'CocoDataset', 'ann_file': 'data/coco/annotations/instances_val2017.json', 'img_prefix': 'data/coco/val2017/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}]}, 'test': {'type': 'CocoDataset', 'ann_file': 'data/coco/annotations/instances_val2017.json', 'img_prefix': 'data/coco/val2017/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}]}}\n",
      "evaluation:{'metric': ['bbox', 'segm']}\n",
      "optimizer:{'type': 'AdamW', 'lr': 2.5e-05, 'weight_decay': 0.0001}\n",
      "optimizer_config:{'grad_clip': {'max_norm': 1, 'norm_type': 2}}\n",
      "lr_config:{'policy': 'step', 'warmup': 'linear', 'warmup_iters': 1000, 'warmup_ratio': 0.001, 'step': [27, 33]}\n",
      "runner:{'type': 'EpochBasedRunner', 'max_epochs': 36}\n",
      "checkpoint_config:{'interval': 1}\n",
      "log_config:{'interval': 50, 'hooks': [{'type': 'TextLoggerHook'}]}\n",
      "custom_hooks:[{'type': 'NumClassCheckHook'}]\n",
      "dist_params:{'backend': 'nccl'}\n",
      "log_level:INFO\n",
      "load_from:None\n",
      "resume_from:None\n",
      "workflow:[('train', 1)]\n",
      "num_stages:6\n",
      "num_proposals:300\n",
      "model:{'type': 'QueryInst', 'pretrained': 'torchvision://resnet50', 'backbone': {'type': 'ResNet', 'depth': 50, 'num_stages': 4, 'out_indices': (0, 1, 2, 3), 'frozen_stages': 1, 'norm_cfg': {'type': 'BN', 'requires_grad': True}, 'norm_eval': True, 'style': 'pytorch'}, 'neck': {'type': 'FPN', 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256, 'start_level': 0, 'add_extra_convs': 'on_input', 'num_outs': 4}, 'rpn_head': {'type': 'EmbeddingRPNHead', 'num_proposals': 300, 'proposal_feature_channel': 256}, 'roi_head': {'type': 'QueryRoIHead', 'num_stages': 6, 'stage_loss_weights': [1, 1, 1, 1, 1, 1], 'proposal_feature_channel': 256, 'bbox_roi_extractor': {'type': 'SingleRoIExtractor', 'roi_layer': {'type': 'RoIAlign', 'output_size': 7, 'sampling_ratio': 2}, 'out_channels': 256, 'featmap_strides': [4, 8, 16, 32]}, 'mask_roi_extractor': {'type': 'SingleRoIExtractor', 'roi_layer': {'type': 'RoIAlign', 'output_size': 14, 'sampling_ratio': 2}, 'out_channels': 256, 'featmap_strides': [4, 8, 16, 32]}, 'bbox_head': [{'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}, {'type': 'DIIHead', 'num_classes': 80, 'num_ffn_fcs': 2, 'num_heads': 8, 'num_cls_fcs': 1, 'num_reg_fcs': 3, 'feedforward_channels': 2048, 'in_channels': 256, 'dropout': 0.0, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 7, 'with_proj': True, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5.0}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2.0}, 'loss_cls': {'type': 'FocalLoss', 'use_sigmoid': True, 'gamma': 2.0, 'alpha': 0.25, 'loss_weight': 2.0}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.5, 0.5, 1.0, 1.0]}}], 'mask_head': [{'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}, {'type': 'DynamicMaskHead', 'dynamic_conv_cfg': {'type': 'DynamicConv', 'in_channels': 256, 'feat_channels': 64, 'out_channels': 256, 'input_feat_shape': 14, 'with_proj': False, 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}}, 'dropout': 0.0, 'num_convs': 4, 'roi_feat_size': 14, 'in_channels': 256, 'conv_kernel_size': 3, 'conv_out_channels': 256, 'class_agnostic': False, 'norm_cfg': {'type': 'BN'}, 'upsample_cfg': {'type': 'deconv', 'scale_factor': 2}, 'loss_dice': {'type': 'DiceLoss', 'loss_weight': 8.0}}]}, 'train_cfg': {'rpn': None, 'rcnn': [{'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}, {'assigner': {'type': 'HungarianAssigner', 'cls_cost': {'type': 'FocalLossCost', 'weight': 2.0}, 'reg_cost': {'type': 'BBoxL1Cost', 'weight': 5.0}, 'iou_cost': {'type': 'IoUCost', 'iou_mode': 'giou', 'weight': 2.0}}, 'sampler': {'type': 'PseudoSampler'}, 'pos_weight': 1, 'mask_size': 28, 'debug': False}]}, 'test_cfg': {'rpn': None, 'rcnn': {'max_per_img': 300, 'mask_thr_binary': 0.5, 'nms': {'type': 'nms', 'iou_threshold': 0.7}}}}\n",
      "total_epochs:36\n",
      "min_values:(480, 512, 544, 576, 608, 640, 672, 704, 736, 768, 800)\n",
      "work_dir:./work_dirs/queryinst_r50_fpn_300_proposals_crop_mstrain_480-800_3x_coco\n",
      "gpu_ids:range(0, 1)\n",
      "seed:None\n"
     ]
    }
   ],
   "source": [
    "for key,value in cfg1.items():\n",
    "    print('{key}:{value}'.format(key = key, value = value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "western-group",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cab0de83fdef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "cfg.data.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "portable-discipline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'CocoDataset',\n",
       " 'ann_file': 'data/coco/annotations/instances_train2017.json',\n",
       " 'img_prefix': 'data/coco/train2017/',\n",
       " 'pipeline': [{'type': 'LoadImageFromFile'},\n",
       "  {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True},\n",
       "  {'type': 'Resize', 'img_scale': (1333, 800), 'keep_ratio': True},\n",
       "  {'type': 'RandomFlip', 'flip_ratio': 0.5},\n",
       "  {'type': 'Normalize',\n",
       "   'mean': [123.675, 116.28, 103.53],\n",
       "   'std': [58.395, 57.12, 57.375],\n",
       "   'to_rgb': True},\n",
       "  {'type': 'Pad', 'size_divisor': 32},\n",
       "  {'type': 'DefaultFormatBundle'},\n",
       "  {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['data']['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alien-directive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'CocoDataset',\n",
       " 'ann_file': 'data/coco/annotations/instances_train2017.json',\n",
       " 'img_prefix': 'data/coco/train2017/',\n",
       " 'pipeline': [{'type': 'LoadImageFromFile'},\n",
       "  {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True},\n",
       "  {'type': 'RandomFlip', 'flip_ratio': 0.5},\n",
       "  {'type': 'AutoAugment',\n",
       "   'policies': [[{'type': 'Resize',\n",
       "      'img_scale': [(480, 1333),\n",
       "       (512, 1333),\n",
       "       (544, 1333),\n",
       "       (576, 1333),\n",
       "       (608, 1333),\n",
       "       (640, 1333),\n",
       "       (672, 1333),\n",
       "       (704, 1333),\n",
       "       (736, 1333),\n",
       "       (768, 1333),\n",
       "       (800, 1333)],\n",
       "      'multiscale_mode': 'value',\n",
       "      'keep_ratio': True}],\n",
       "    [{'type': 'Resize',\n",
       "      'img_scale': [(400, 1333), (500, 1333), (600, 1333)],\n",
       "      'multiscale_mode': 'value',\n",
       "      'keep_ratio': True},\n",
       "     {'type': 'RandomCrop',\n",
       "      'crop_type': 'absolute_range',\n",
       "      'crop_size': (384, 600),\n",
       "      'allow_negative_crop': True},\n",
       "     {'type': 'Resize',\n",
       "      'img_scale': [(480, 1333),\n",
       "       (512, 1333),\n",
       "       (544, 1333),\n",
       "       (576, 1333),\n",
       "       (608, 1333),\n",
       "       (640, 1333),\n",
       "       (672, 1333),\n",
       "       (704, 1333),\n",
       "       (736, 1333),\n",
       "       (768, 1333),\n",
       "       (800, 1333)],\n",
       "      'multiscale_mode': 'value',\n",
       "      'override': True,\n",
       "      'keep_ratio': True}]]},\n",
       "  {'type': 'Normalize',\n",
       "   'mean': [123.675, 116.28, 103.53],\n",
       "   'std': [58.395, 57.12, 57.375],\n",
       "   'to_rgb': True},\n",
       "  {'type': 'Pad', 'size_divisor': 32},\n",
       "  {'type': 'DefaultFormatBundle'},\n",
       "  {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg1['data']['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "satellite-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_from_cfg(cfg, registry, default_args=None):\n",
    "    \"\"\"Build a module from config dict.\n",
    "\n",
    "    Args:\n",
    "        cfg (dict): Config dict. It should at least contain the key \"type\".\n",
    "        registry (:obj:`Registry`): The registry to search the type from.\n",
    "        default_args (dict, optional): Default initialization arguments.\n",
    "\n",
    "    Returns:\n",
    "        object: The constructed object.\n",
    "    \"\"\"\n",
    "    if not isinstance(cfg, dict):\n",
    "        raise TypeError(f'cfg must be a dict, but got {type(cfg)}')\n",
    "    if 'type' not in cfg:\n",
    "        if default_args is None or 'type' not in default_args:\n",
    "            raise KeyError(\n",
    "                '`cfg` or `default_args` must contain the key \"type\", '\n",
    "                f'but got {cfg}\\n{default_args}')\n",
    "\n",
    "    if not (isinstance(default_args, dict) or default_args is None):\n",
    "        raise TypeError('default_args must be a dict or None, '\n",
    "                        f'but got {type(default_args)}')\n",
    "\n",
    "    args = cfg.copy()\n",
    "\n",
    "    if default_args is not None:\n",
    "        for name, value in default_args.items():\n",
    "            args.setdefault(name, value)\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "editorial-banking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'CocoDataset',\n",
       " 'ann_file': 'data/coco/annotations/instances_train2017.json',\n",
       " 'img_prefix': 'data/coco/train2017/',\n",
       " 'pipeline': [{'type': 'LoadImageFromFile'},\n",
       "  {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True},\n",
       "  {'type': 'Resize', 'img_scale': (1333, 800), 'keep_ratio': True},\n",
       "  {'type': 'RandomFlip', 'flip_ratio': 0.5},\n",
       "  {'type': 'Normalize',\n",
       "   'mean': [123.675, 116.28, 103.53],\n",
       "   'std': [58.395, 57.12, 57.375],\n",
       "   'to_rgb': True},\n",
       "  {'type': 'Pad', 'size_divisor': 32},\n",
       "  {'type': 'DefaultFormatBundle'},\n",
       "  {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_from_cfg(cfg['data']['train'], registry=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "pregnant-fetish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'CocoDataset',\n",
       " 'ann_file': 'data/coco/annotations/instances_train2017.json',\n",
       " 'img_prefix': 'data/coco/train2017/',\n",
       " 'pipeline': [{'type': 'LoadImageFromFile'},\n",
       "  {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True},\n",
       "  {'type': 'RandomFlip', 'flip_ratio': 0.5},\n",
       "  {'type': 'AutoAugment',\n",
       "   'policies': [[{'type': 'Resize',\n",
       "      'img_scale': [(480, 1333),\n",
       "       (512, 1333),\n",
       "       (544, 1333),\n",
       "       (576, 1333),\n",
       "       (608, 1333),\n",
       "       (640, 1333),\n",
       "       (672, 1333),\n",
       "       (704, 1333),\n",
       "       (736, 1333),\n",
       "       (768, 1333),\n",
       "       (800, 1333)],\n",
       "      'multiscale_mode': 'value',\n",
       "      'keep_ratio': True}],\n",
       "    [{'type': 'Resize',\n",
       "      'img_scale': [(400, 1333), (500, 1333), (600, 1333)],\n",
       "      'multiscale_mode': 'value',\n",
       "      'keep_ratio': True},\n",
       "     {'type': 'RandomCrop',\n",
       "      'crop_type': 'absolute_range',\n",
       "      'crop_size': (384, 600),\n",
       "      'allow_negative_crop': True},\n",
       "     {'type': 'Resize',\n",
       "      'img_scale': [(480, 1333),\n",
       "       (512, 1333),\n",
       "       (544, 1333),\n",
       "       (576, 1333),\n",
       "       (608, 1333),\n",
       "       (640, 1333),\n",
       "       (672, 1333),\n",
       "       (704, 1333),\n",
       "       (736, 1333),\n",
       "       (768, 1333),\n",
       "       (800, 1333)],\n",
       "      'multiscale_mode': 'value',\n",
       "      'override': True,\n",
       "      'keep_ratio': True}]]},\n",
       "  {'type': 'Normalize',\n",
       "   'mean': [123.675, 116.28, 103.53],\n",
       "   'std': [58.395, 57.12, 57.375],\n",
       "   'to_rgb': True},\n",
       "  {'type': 'Pad', 'size_divisor': 32},\n",
       "  {'type': 'DefaultFormatBundle'},\n",
       "  {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_from_cfg(cfg1['data']['train'], registry=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "promising-patient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(build_from_cfg(cfg1['data']['train'], registry=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "anonymous-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple1 = tuple((1, 2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bound-departure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "print(tuple1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "junior-jungle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tuple1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "successful-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.rand((2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "further-newark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.Size([2, 3])'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(tensor1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "golden-criterion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8155, 0.0928, 0.2000],\n",
      "        [0.5605, 0.5539, 0.8906]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "entertaining-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "np1 = np.asarray([[[ 800., 1067.,  800., 1067.]],[[ 800., 1174.,  800., 1174.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fourth-thing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "civilian-accent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 800., 1067.,  800., 1067.]],\n",
       "\n",
       "       [[ 800., 1174.,  800., 1174.]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "protected-addition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 800., 1067.,  800., 1067.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "interim-birmingham",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1921, 0.0380, 0.7934, 0.4240, 0.6503])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_lvls = torch.rand(5)\n",
    "target_lvls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sticky-judges",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True, False,  True, False])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = target_lvls < 0.5\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "continental-constitution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inds = mask.nonzero(as_tuple=False).squeeze(1)\n",
    "inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "duplicate-framework",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6279, 0.6949],\n",
       "        [0.4297, 0.3720],\n",
       "        [0.1383, 0.0598],\n",
       "        [0.8139, 0.2525],\n",
       "        [0.6792, 0.7101]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rois = torch.rand((5, 2))\n",
    "rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fuzzy-panel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6279, 0.6949],\n",
       "        [0.4297, 0.3720],\n",
       "        [0.8139, 0.2525]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rois_ = rois[inds]\n",
    "rois_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "celtic-sauce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3276275381d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m dict1 = {'bboxes': array([[  8.21, 193.18, 316.27, 605.29],\n\u001b[0m\u001b[1;32m      2\u001b[0m        [  0.  ,   0.  , 476.32, 482.93]], dtype=float32), 'labels': array([15,  1]), 'bboxes_ignore': array([], shape=(0, 4), dtype=float32), 'masks': [[[28.75, 540.94, 39.7, 456.05, 27.38, 404.02, 34.23, 343.78, 42.44, 323.25, 27.38, 278.07, 12.32, 224.67, 8.21, 208.24, 54.77, 217.82, 115.01, 215.09, 146.5, 193.18, 171.14, 200.02, 153.34, 236.99, 167.03, 250.68, 158.82, 267.11, 147.87, 295.86, 231.38, 315.03, 268.35, 350.63, 299.84, 382.12, 306.68, 416.35, 316.27, 467.0, 309.42, 523.14, 292.99, 536.83, 295.73, 556.0, 295.73, 579.27, 217.69, 605.29, 123.22, 605.29, 109.53, 592.96, 142.39, 577.9, 139.65, 534.09, 88.99, 519.03, 67.09, 565.58, 21.91, 551.89]], [[324.76, 432.3, 409.92, 351.47, 459.0, 241.77, 470.55, 178.26, 476.32, 98.87, 461.89, 36.81, 439.03, 0.0, 290.61, 0.0, 275.18, 0.0, 160.27, 0.0, 53.87, 0.0, 0.0, 0.0, 0.0, 106.15, 0.0, 116.79, 0.0, 116.79, 1.74, 122.11, 5.01, 472.73, 43.23, 482.93, 38.13, 377.18, 43.23, 332.58, 25.39, 270.15, 8.83, 224.28, 25.39, 220.46, 52.15, 221.74, 99.29, 215.37, 142.61, 207.72, 161.72, 198.8, 168.09, 215.37, 170.64, 265.06, 169.36, 280.34, 174.46, 293.09, 222.88, 300.73, 254.73, 326.21, 280.21, 379.72, 296.77, 411.58]]], 'seg_map': '000000525851.png'}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'array' is not defined"
     ]
    }
   ],
   "source": [
    "dict1 = {'bboxes': array([[  8.21, 193.18, 316.27, 605.29],\n",
    "       [  0.  ,   0.  , 476.32, 482.93]], dtype=float32), 'labels': array([15,  1]), 'bboxes_ignore': array([], shape=(0, 4), dtype=float32), 'masks': [[[28.75, 540.94, 39.7, 456.05, 27.38, 404.02, 34.23, 343.78, 42.44, 323.25, 27.38, 278.07, 12.32, 224.67, 8.21, 208.24, 54.77, 217.82, 115.01, 215.09, 146.5, 193.18, 171.14, 200.02, 153.34, 236.99, 167.03, 250.68, 158.82, 267.11, 147.87, 295.86, 231.38, 315.03, 268.35, 350.63, 299.84, 382.12, 306.68, 416.35, 316.27, 467.0, 309.42, 523.14, 292.99, 536.83, 295.73, 556.0, 295.73, 579.27, 217.69, 605.29, 123.22, 605.29, 109.53, 592.96, 142.39, 577.9, 139.65, 534.09, 88.99, 519.03, 67.09, 565.58, 21.91, 551.89]], [[324.76, 432.3, 409.92, 351.47, 459.0, 241.77, 470.55, 178.26, 476.32, 98.87, 461.89, 36.81, 439.03, 0.0, 290.61, 0.0, 275.18, 0.0, 160.27, 0.0, 53.87, 0.0, 0.0, 0.0, 0.0, 106.15, 0.0, 116.79, 0.0, 116.79, 1.74, 122.11, 5.01, 472.73, 43.23, 482.93, 38.13, 377.18, 43.23, 332.58, 25.39, 270.15, 8.83, 224.28, 25.39, 220.46, 52.15, 221.74, 99.29, 215.37, 142.61, 207.72, 161.72, 198.8, 168.09, 215.37, 170.64, 265.06, 169.36, 280.34, 174.46, 293.09, 222.88, 300.73, 254.73, 326.21, 280.21, 379.72, 296.77, 411.58]]], 'seg_map': '000000525851.png'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "general-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg = [[200.69, 130.08, 199.66, 138.81, 199.66, 143.42, 209.92, 141.88, 215.56, 140.34, 215.56, 131.11, 220.18, 129.57, 222.23, 125.98, 222.23, 125.47, 224.8, 122.9, 230.95, 129.06, 236.6, 139.83, 235.57, 151.12, 240.19, 152.66, 242.75, 140.86, 238.13, 130.08, 227.87, 120.34, 228.9, 114.69, 239.16, 117.26, 236.08, 108.54, 230.95, 102.38, 224.8, 95.71, 207.87, 94.69, 196.07, 99.82, 192.99, 109.05, 190.94, 115.21, 182.73, 127.52, 178.63, 132.65, 184.27, 133.67, 188.37, 127.52, 191.96, 123.93, 196.58, 121.88, 198.12, 123.41, 199.15, 129.57, 199.66, 129.57]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "downtown-reason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 70)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(seg).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rural-auditor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rle = [1, 2, 3]\n",
    "sum(rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "numeric-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_bboxes = torch.rand((2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "filled-prior",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_bboxes[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "twenty-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_bboxes = torch.rand((4, 4))\n",
    "neg_bboxes = torch.rand((2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "maritime-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.cat([pos_bboxes, neg_bboxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "governing-elimination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "graphic-billy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps = torch.rand((3, 4))\n",
    "num_bboxes = 4\n",
    "overlaps.new_full((num_bboxes, ), -1, dtype=torch.long).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "maritime-prototype",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1, -1, -1, -1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps.new_full((num_bboxes, ), -1, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "joined-fiction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8525, 0.8651, 0.4811, 0.7974],\n",
       "        [0.1863, 0.8352, 0.3759, 0.7584],\n",
       "        [0.9045, 0.3167, 0.7406, 0.5487]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_overlaps, argmax_overlaps = overlaps.max(dim=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "burning-notice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9045, 0.8651, 0.7406, 0.7974])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fewer-pierce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 2, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax_overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "substantial-province",
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_gt_inds = overlaps.new_full((num_bboxes, ), -1, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "working-shoot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1, -1, -1, -1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned_gt_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "confirmed-external",
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_gt_inds[(max_overlaps >= 0)& (max_overlaps < 0.8)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bigger-flour",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1, -1,  0,  0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned_gt_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "helpful-mercury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_inds = max_overlaps >= 0.8\n",
    "pos_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "binary-faculty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 1, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned_gt_inds[pos_inds] = argmax_overlaps[pos_inds] + 1 \n",
    "assigned_gt_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "silver-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_max_overlaps, gt_argmax_overlaps = overlaps.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "settled-albert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8651, 0.8352, 0.9045])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_max_overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "checked-western",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_argmax_overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "vertical-hungarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "a.index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "governmental-monthly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.index(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "accompanied-current",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.index(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "floral-explorer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(gt_max_overlaps > 0).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "tropical-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand((3))\n",
    "b = torch.rand((3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "loose-crack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([a, b],0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-parliament",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
